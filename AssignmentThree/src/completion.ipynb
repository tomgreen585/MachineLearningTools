{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from csv files -> na values are '?', '0/4', -1 as identified in eda\n",
    "\n",
    "alternative = pd.read_csv('training-data/alternative.csv', na_values=['?', '0/4', -1])\n",
    "blues = pd.read_csv('training-data/blues.csv', na_values=['?', '0/4', -1])\n",
    "classical = pd.read_csv('training-data/classical.csv', na_values=['?', '0/4', -1])\n",
    "comedy = pd.read_csv('training-data/comedy.csv', na_values=['?', '0/4', -1])\n",
    "folk = pd.read_csv('training-data/folk.csv', na_values=['?', '0/4', -1])\n",
    "hiphop = pd.read_csv('training-data/hip-hop.csv', na_values=['?', '0/4', -1])\n",
    "jazz = pd.read_csv('training-data/jazz.csv', na_values=['?', '0/4', -1])\n",
    "opera = pd.read_csv('training-data/opera.csv', na_values=['?', '0/4', -1])\n",
    "pop = pd.read_csv('training-data/pop.csv', na_values=['?', '0/4', -1])\n",
    "rnb = pd.read_csv('training-data/rb.csv', na_values=['?', '0/4', -1])\n",
    "\n",
    "df = pd.concat([alternative, blues, classical, comedy, folk, hiphop, jazz, opera, pop, rnb], axis=0) #concatenate all genre dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['instance_id', 'track_id', 'track_name', 'key', 'mode'], axis=1) #drop columns that are not useful for classification\n",
    "train_data = df.drop(['genre'], axis=1) #drop target column\n",
    "test_data = df['genre'] #target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify numerical and cateogircal features for encoding\n",
    "\n",
    "numerical_features = ['popularity', 'acousticness', 'danceability',\n",
    "                      'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'duration_ms']\n",
    "\n",
    "categorical_features = ['artist_name', 'time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform imputation scaling encoding\n",
    "\n",
    "si_num = SimpleImputer(strategy='median') #initialize imputer for numerical features\n",
    "scaler = StandardScaler() #initialize standard scaler for numerical features\n",
    "si_cat = SimpleImputer(strategy='most_frequent') #initialize imputer for categorical features\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False) #initialize one hot encoder for categorical features\n",
    "\n",
    "train_data[numerical_features] = si_num.fit_transform(train_data[numerical_features]) #impute missing values in numerical features\n",
    "train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features]) #scale numerical features\n",
    "\n",
    "train_data[categorical_features] = si_cat.fit_transform(train_data[categorical_features]) #impute missing values in categorical features\n",
    "encoded_cat_features = ohe.fit_transform(train_data[categorical_features]) #encode categorical features\n",
    "encoded_cat_df = pd.DataFrame(encoded_cat_features, columns=ohe.get_feature_names_out(categorical_features)) #convert encoded features to dataframe\n",
    "\n",
    "train_data_numerical_df = pd.DataFrame(train_data[numerical_features]).reset_index(drop=True) #sort index issues\n",
    "encoded_cat_df = encoded_cat_df.reset_index(drop=True) #sort index issues\n",
    "\n",
    "processed_features = pd.concat([train_data_numerical_df, encoded_cat_df], axis=1) #concatenate numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training into train/test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_features, test_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode genre values in target test sets\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize classifiers\n",
    "\n",
    "rf = RandomForestClassifier(random_state=309)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "gnb = GradientBoostingClassifier(n_estimators=20)\n",
    "mlpc = MLPClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training rf model\n",
    "\n",
    "rf.fit(x_train, y_train) #fit rf\n",
    "rf_pred = rf.predict(x_test) #predict rf\n",
    "rf_acc = accuracy_score(y_test, rf_pred) #calc accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training gnb model\n",
    "\n",
    "gnb.fit(x_train, y_train) #fit gnb\n",
    "gnb_pred = gnb.predict(x_test) #predict gnb\n",
    "gnb_acc = accuracy_score(y_test, gnb_pred) #calc accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training mlpc model\n",
    "\n",
    "mlpc.fit(x_train, y_train) #fit mlpc\n",
    "mlpc_pred = mlpc.predict(x_test) #predict mlpc\n",
    "mlpc_acc = accuracy_score(y_test, mlpc_pred) #calc accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training stacking model\n",
    "\n",
    "combination = StackingClassifier(estimators=[('rf', rf), ('gnb', gnb), ('mlpc', mlpc)], cv=\"prefit\") #stack rf, gnb, mlpc in model with cv as prefit\n",
    "combination.fit(x_train, y_train) #fit model\n",
    "combination_predictions = combination.predict(x_test) #predict model\n",
    "combination_accuracy = accuracy_score(y_test, combination_predictions) #calc accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.6772\n",
      "Gradient Boosting Accuracy:  0.6436\n",
      "MLPC Accuracy:  0.7801\n",
      "Stacking Accuracy:  0.7509\n"
     ]
    }
   ],
   "source": [
    "#print out accuracies\n",
    "\n",
    "print(\"Random Forest Accuracy: \", rf_acc)\n",
    "print(\"Gradient Boosting Accuracy: \", gnb_acc)\n",
    "print(\"MLPC Accuracy: \", mlpc_acc)\n",
    "print(\"Stacking Accuracy: \", combination_accuracy)\n",
    "\n",
    "# NORMAL with removed duration_ms, key, mode\n",
    "# Random Forest Accuracy: 0.6234\n",
    "# Gradient Boosting Accuracy: 0.6268\n",
    "# MLPC Accuracy: 0.6515\n",
    "# Stacking Accuracy: 0.6223\n",
    "\n",
    "# NORMAL with removed duration_ms\n",
    "# Random Forest Accuracy: 0.6233\n",
    "# Gradient Boosting Accuracy: 0.626\n",
    "# MLPC Accuracy: 0.6366\n",
    "# Stacking Accuracy: 0.6223\n",
    "\n",
    "# NORMAL with removed key, mode\n",
    "# Random Forest Accuracy: 0.6271\n",
    "# Gradient Boosting Accuracy: 0.6269\n",
    "# MLPC Accuracy: 0.6525\n",
    "# Stacking Accuracy: 0.6266\n",
    "\n",
    "# NORMAL with everything\n",
    "# Random Forest Accuracy: 0.6276\n",
    "# Gradient Boosting Accuracy: 0.6269\n",
    "# MLPC Accuracy: 0.6399\n",
    "# Stacking Accuracy: 0.6288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read testing data -> na values are '?', '0/4', -1 as identified in eda\n",
    "\n",
    "test_df = pd.read_csv('testing-data/testing-instances.csv', na_values=['?', '0/4', -1])\n",
    "id = test_df['instance_id']\n",
    "testing = test_df.drop(['instance_id', 'track_id', 'track_name', 'key', 'mode'], axis=1) #drop columns that are not useful for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the same preprocessing as the training data\n",
    "\n",
    "testing[numerical_features] = si_num.transform(testing[numerical_features]) #impute missing values in numerical features\n",
    "testing[numerical_features] = scaler.transform(testing[numerical_features]) #scale numerical features\n",
    "\n",
    "testing[categorical_features] = si_cat.transform(testing[categorical_features]) #impute missing values in categorical features\n",
    "encoded_testing_cat_features = ohe.transform(testing[categorical_features]) #encode categorical features\n",
    "encoded_testing_cat_df = pd.DataFrame(encoded_testing_cat_features, columns=ohe.get_feature_names_out(categorical_features)) #convert encoded features to dataframe\n",
    "\n",
    "testing_numerical_df = pd.DataFrame(testing[numerical_features]).reset_index(drop=True) #sort index issues\n",
    "encoded_testing_cat_df = encoded_testing_cat_df.reset_index(drop=True) #sort index issues\n",
    "\n",
    "processed_testing_features = pd.concat([testing_numerical_df, encoded_testing_cat_df], axis=1) #concatenate numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use mlpc model as it had the highest accuracy\n",
    "\n",
    "mlpc_test_pred = mlpc.predict(processed_testing_features) #predict mlpc on testing data\n",
    "mlpc_test_pred = le.inverse_transform(mlpc_test_pred) #inverse transform encoded genre values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPC Predictions:  ['Classical' 'Hip-Hop' 'Blues' 'Jazz' 'Jazz' 'R&B' 'R&B' 'Pop' 'Opera'\n",
      " 'Jazz']\n"
     ]
    }
   ],
   "source": [
    "#print first 10 values to check genre predictions of model\n",
    "\n",
    "print('MLPC Predictions: ', mlpc_test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFrame with test-instance ids and pred-genre\n",
    "\n",
    "test_mlpc_normal = pd.DataFrame(id)\n",
    "test_mlpc_normal['genre'] = mlpc_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to csv\n",
    "\n",
    "test_mlpc_normal.to_csv('output-data/test_mlpc_normal.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
